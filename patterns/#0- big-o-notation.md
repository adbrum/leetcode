# ğŸ“˜ Big O Notation

## ğŸ”¹ O(1) â€“ Tempo Constante

**DefiniÃ§Ã£o:** O tempo de execuÃ§Ã£o **nÃ£o depende** do tamanho da entrada (`n`).

**Exemplo:**

```python
def get_first_element(arr):
    return arr[0]  # sempre retorna o primeiro elemento
```
**AnÃ¡lise:**

* NÃ£o importa se `arr` tem 10 ou 10 milhÃµes de elementos. A operaÃ§Ã£o de aceder ao Ã­ndice `[0]` leva o **mesmo tempo**.

**Complexidade:** `O(1)`

## ğŸ”¹ O(`\log n`) â€“ Tempo LogarÃ­tmico

**DefiniÃ§Ã£o:** O algoritmo reduz o problema pela **metade** a cada passo.

**Uso Comum:** Muito comum em algoritmos de **busca binÃ¡ria** (*binary search*) e estruturas de dados baseadas em Ã¡rvores.

**Exemplo:**

```python
def binary_search(arr, target):
    l, r = 0, len(arr) - 1
    while l <= r:
        mid = (l + r) // 2
        if arr[mid] == target:
            return mid
        elif arr[mid] < target:
            l = mid + 1
        else:
            r = mid - 1
    return -1
```
**AnÃ¡lise:**

* A cada iteraÃ§Ã£o, o intervalo de pesquisa diminui pela **metade**.
* Para `n = 1.000.000`, sÃ£o necessÃ¡rios no mÃ¡ximo `\approx 20` passos (`\log_2 1.000.000 \approx 19.9`). O crescimento Ã© extremamente lento e eficiente.

**Complexidade:** `O(\log n)`

## ğŸ”¹ O(`n`) â€“ Tempo Linear

**DefiniÃ§Ã£o:** O tempo de execuÃ§Ã£o Ã© diretamente proporcional ao tamanho da entrada (`n`). O algoritmo percorre todos os elementos da entrada **exatamente uma vez**.

**Exemplo:**

```python
def find_max(arr):
    maximum = arr[0]
    for num in arr:
        if num > maximum:
            maximum = num
    return maximum
```
**AnÃ¡lise:**

* Para encontrar o valor mÃ¡ximo, o algoritmo **precisa olhar cada elemento** do *array* uma Ãºnica vez.
* Se a entrada dobrar de tamanho (de `n` para `2n`), o tempo de execuÃ§Ã£o tambÃ©m dobra.

**Complexidade:** `O(n)`

## ğŸ”¹ O(`n \log n`) â€“ Tempo Quase Linear

**DefiniÃ§Ã£o:** O algoritmo geralmente envolve dividir o problema em subproblemas (o fator `\log n`) e depois fazer um trabalho linear (`n`) para combinÃ¡-los ou resolvÃª-los.

**Uso Comum:** Comum em algoritmos de **ordenaÃ§Ã£o eficiente** como *Merge Sort*, *Quick Sort* (caso mÃ©dio) ou *Heap Sort*.

**Exemplo (Merge Sort simplificado):**

```python
def merge_sort(arr):
    if len(arr) <= 1:
        return arr
    mid = len(arr) // 2
    left = merge_sort(arr[:mid])
    right = merge_sort(arr[mid:])
    return merge(left, right)

def merge(left, right):
    result = []
    while left and right:
        if left[0] < right[0]:
            result.append(left.pop(0))
        else:
            result.append(right.pop(0))
    return result + left + right
```
**AnÃ¡lise (Merge Sort):**

* **DivisÃ£o (`\log n`):** O processo de dividir o *array* recursivamente em metades resulta em `\log n` **nÃ­veis** de recursÃ£o (semelhante ao *binary search*).
* **CombinaÃ§Ã£o (`n`):** Em cada nÃ­vel da recursÃ£o, o processo de **`merge` (combinar)** todos os elementos das sub-listas leva um tempo total de `O(n)`.
* **Total:** `(\text{Trabalho por NÃ­vel}) \times (\text{NÃ­veis}) = n \times \log n`.

**Complexidade:** `O(n \log n)`

## ğŸ”¹ O(`n^2`) â€“ Tempo QuadrÃ¡tico

**DefiniÃ§Ã£o:** O tempo de execuÃ§Ã£o cresce proporcionalmente ao **quadrado** do tamanho da entrada (`n`).

**Uso Comum:** Algoritmos com **dois *loops* aninhados**, comuns em problemas de comparaÃ§Ã£o de todos os pares de elementos.

**Exemplo:**

```python
def has_duplicates(arr):
    for i in range(len(arr)):
        for j in range(i+1, len(arr)):
            if arr[i] == arr[j]:
                return True
    return False
```
**AnÃ¡lise:**

* Cada elemento no *array* Ã© comparado com **todos os outros** elementos restantes.
* A cada iteraÃ§Ã£o do *loop* externo, o *loop* interno executa aproximadamente `n` vezes. O nÃºmero total de operaÃ§Ãµes Ã© `\approx n \times n`.
* Para `n = 1000`, o nÃºmero de comparaÃ§Ãµes Ã© atÃ© `\approx 500.000`. O desempenho deteriora-se rapidamente com o aumento de `n`.

**Complexidade:** `O(n^2)`

## ğŸ”¹ O(`2^n`) â€“ Tempo Exponencial

**DefiniÃ§Ã£o:** O tempo de execuÃ§Ã£o **dobra** a cada aumento unitÃ¡rio no tamanho da entrada (`n`). Ã‰ uma complexidade que cresce de forma explosiva.

**Uso Comum:** TÃ­pico em algoritmos de **forÃ§a bruta** (*brute force*), onde todas as **combinaÃ§Ãµes ou *subsets* possÃ­veis** devem ser gerados (por exemplo, o Problema do Caixeiro Viajante, ou a recursÃ£o ingÃ©nua).

**Exemplo (Fibonacci recursivo sem memoizaÃ§Ã£o):**

```python
def fib(n):
    if n <= 1:
        return n
    return fib(n-1) + fib(n-2)
```
**AnÃ¡lise:**

* O algoritmo cria uma **Ã¡rvore de chamadas binÃ¡ria** onde cada nÃ³ (exceto a base) faz duas chamadas recursivas.
* O nÃºmero de operaÃ§Ãµes cresce **exponencialmente** com `n`.
* Para `n = 40`, jÃ¡ sÃ£o feitas **`\approx 1` bilhÃ£o de chamadas**. Isto torna o algoritmo impraticÃ¡vel para grandes valores de `n`.

**Complexidade:** `O(2^n)`

## ğŸ”¹ O(`n!`) â€“ Tempo Fatorial

**DefiniÃ§Ã£o:** O tempo de execuÃ§Ã£o cresce de forma **absurdamente rÃ¡pida** e Ã© a complexidade mais lenta, exceto por `O(n^n)`. O tempo Ã© proporcional ao fatorial do tamanho da entrada (`n`).

**Uso Comum:** TÃ­pico em algoritmos que precisam gerar ou processar **todas as permutaÃ§Ãµes possÃ­veis** de um conjunto (exemplo: soluÃ§Ãµes exatas para o Problema do Caixeiro Viajante).

**Exemplo:**

```python
import itertools

def all_permutations(arr):
    # Gera todas as permutaÃ§Ãµes do array
    return list(itertools.permutations(arr))
```
**AnÃ¡lise:**

* O nÃºmero de operaÃ§Ãµes Ã© igual ao **nÃºmero total de permutaÃ§Ãµes** que podem ser formadas com os `n` elementos.
* O crescimento Ã© impraticÃ¡vel mesmo para valores pequenos de `n`.
* Para `n = 10`, jÃ¡ sÃ£o `10! = 3.628.800` permutaÃ§Ãµes. Para `n = 20`, o nÃºmero Ã© astronÃ³mico.

**Complexidade:** `O(n!)`

# ğŸ“‰ Resumo da NotaÃ§Ã£o Big O

A NotaÃ§Ã£o Big O descreve o desempenho (tempo ou espaÃ§o) de um algoritmo Ã  medida que o tamanho da entrada (`n`) cresce.

---

| NotaÃ§Ã£o | Nome | DescriÃ§Ã£o | Exemplo TÃ­pico |
| :--- | :--- | :--- | :--- |
| **`O(1)`** | Constante | O tempo de execuÃ§Ã£o Ã© **independente** de `n`. | Acesso direto a um Ã­ndice de array ou *hash map*. |
| **`O(\log n)`** | LogarÃ­tmica | O problema Ã© **reduzido pela metade** em cada passo. | Busca BinÃ¡ria (*Binary Search*). |
| **`O(n)`** | Linear | O tempo de execuÃ§Ã£o Ã© **diretamente proporcional** a `n`. | Percorrer um array com um *loop* simples. |
| **`O(n \log n)`** | Quase Linear | Resultado de dividir o problema (`\log n`) e resolvÃª-lo linearmente (`n`). | Algoritmos de ordenaÃ§Ã£o eficientes: *Merge Sort*, *Quick Sort* (caso mÃ©dio). |
| **`O(n^2)`** | QuadrÃ¡tica | O tempo cresce com o **quadrado** de `n`. | Dois *loops* aninhados (comparar todos os pares de elementos). |
| **`O(2^n)`** | Exponencial | O tempo **dobra** a cada adiÃ§Ã£o em `n`. | GeraÃ§Ã£o de *subsets* ou Fibonacci recursivo ingÃ©nuo. |
| **`O(n!)`** | Fatorial | O tempo cresce de forma **extremamente rÃ¡pida**. | GeraÃ§Ã£o de todas as permutaÃ§Ãµes. |

---

### Ordem de EficiÃªncia (Melhor para Pior)

``O(1) < O(\log n) < O(n) < O(n \log n) < O(n^2) < O(2^n) < O(n!)``